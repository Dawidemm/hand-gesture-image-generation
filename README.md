# hand-gesture-image-generation

## Description
This project is part of the coursework for the Computational Intelligence course within the Master's program in Automation and Robotics at the AGH University of Krakow. The project aims to investigate the influence of classifier training on real-world data versus data generated by a Generative Adversarial Network (GAN), as well as on shuffled data.

## Installation

1. Clone the repository:

    ```bash
    git clone https://github.com/Dawidemm/hand-gesture-image-generation
    cd hand-gesture-image-generation
    ```

2. Python Version:

   This project is developed using Python version 3.10.13.

3. Virtual Environment:

   It is recommended to use a virtual environment to manage dependencies and isolate the project environment.

4. Install the project:

    After activating the virtual environment, navigate to the project directory and install the project using the following command:

    ```bash
    pip install .
    ```

## Data Source

The data used in this project is sourced from the "Rock-Paper-Scissors-Dataset" available on Kaggle. The dataset consists of images representing hand gestures for the rock, paper, and scissors signs. This dataset can be accessed through the following link:

[Rock Paper Scissors Dataset](https://www.kaggle.com/datasets/alexandredj/rock-paper-scissors-dataset)

The dataset is valuable for training and evaluating machine learning models for hand gesture recognition tasks. It contains a variety of hand poses and backgrounds, offering a diverse set of images for experimentation and analysis.